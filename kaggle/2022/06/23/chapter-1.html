<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The road to worlds number 1, Chapter 1 The first kaggle competition | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="The road to worlds number 1, Chapter 1 The first kaggle competition" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="What does it take to become world-wide #1 in competitive machine learning? Here, I want to recap my journey and share major insights I gained along the way to becoming rank" />
<meta property="og:description" content="What does it take to become world-wide #1 in competitive machine learning? Here, I want to recap my journey and share major insights I gained along the way to becoming rank" />
<link rel="canonical" href="https://christofhenkel.github.io/dieters-blog/kaggle/2022/06/23/chapter-1.html" />
<meta property="og:url" content="https://christofhenkel.github.io/dieters-blog/kaggle/2022/06/23/chapter-1.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://christofhenkel.github.io/dieters-blog/images/tf_speech_thumbnail.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-06-23T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://christofhenkel.github.io/dieters-blog/images/tf_speech_thumbnail.png" />
<meta property="twitter:title" content="The road to worlds number 1, Chapter 1 The first kaggle competition" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-06-23T00:00:00-05:00","datePublished":"2022-06-23T00:00:00-05:00","description":"What does it take to become world-wide #1 in competitive machine learning? Here, I want to recap my journey and share major insights I gained along the way to becoming rank","headline":"The road to worlds number 1, Chapter 1 The first kaggle competition","image":"https://christofhenkel.github.io/dieters-blog/images/tf_speech_thumbnail.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://christofhenkel.github.io/dieters-blog/kaggle/2022/06/23/chapter-1.html"},"url":"https://christofhenkel.github.io/dieters-blog/kaggle/2022/06/23/chapter-1.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/dieters-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://christofhenkel.github.io/dieters-blog/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/dieters-blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/dieters-blog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/dieters-blog/about/">About Me</a><a class="page-link" href="/dieters-blog/search/">Search</a><a class="page-link" href="/dieters-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">The road to worlds number 1, Chapter 1 The first kaggle competition</h1><p class="page-description">What does it take to become world-wide \#1 in competitive machine learning? Here, I want to recap my journey and share major insights I gained along the way to becoming rank</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-06-23T00:00:00-05:00" itemprop="datePublished">
        Jun 23, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/dieters-blog/categories/#kaggle">kaggle</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#about-kaggle">About Kaggle</a></li>
<li class="toc-entry toc-h2"><a href="#how-it-started">How it started</a></li>
<li class="toc-entry toc-h2"><a href="#the-first-competition">The first competition</a></li>
</ul><h2 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>

<p>What does it take to become world-wide #1 in competitive machine learning? Here, I want to recap my journey and share major insights I gained along the way to becoming rank #1 in the competitions ranking on Kaggle, the hardest thing I have done in my entire life.</p>

<p>Starting as a Kaggle “goose” with zero data science knowledge four years ago, I am still astonished how my career path turned out. Especially, how completely self-teaching basics of machine learning by public available content (e.g. youtube, fastai) and exclusively advancing the knowledge by doing Kaggle competitions, ultimately resulted not only in the top spot within the biggest community of competitive data science, but also a dream job at NVIDIA, one of the most innovative and respected companies in the world when it comes to AI. Although the path was challenging with more than 50 competitions done in over four years it shows that practically everybody can achieve the same with enough dedication and discipline. As such, I want to encourage data science beginners or even people who are just curious about the topic of AI without any prior knowledge to start their own journey.</p>
<h2 id="about-kaggle">
<a class="anchor" href="#about-kaggle" aria-hidden="true"><span class="octicon octicon-link"></span></a>About Kaggle</h2>

<p>Before diving into my journey I want to talk about Kaggle as it is a huge part of it. When I started, I thought of it as just a website that hosts machine learning competitions, but it is so much more. It offers a platform to share knowledge in form of discussions and code-kernels and motivates learning and sharing by awarding tiers and medals.</p>

<p>The amount and the recency of knowledge that can be found on Kaggle is amazing. On the one hand, detailed solution summaries of a past competition, which are shared by top performing teams work like a concentrated place of knowledge for specific tasks (for example, computer vision - instance segmentation, NLP - question answering). On the other hand, competitors, especially at the highest level, are forced to keep up and implement the latest research papers in order to stand out and finish in top spots in competitions. Hence, top solutions often represent or even extend the current state of the art for a given problem.</p>

<p>Furthermore the competitive aspect is a huge source of motivation. There is nothing more motivating than to see your work paying-off in climbing the public leaderboard (LB) during the weeks of a competition and the tension of the final hours when your private LB score, determining your final result,  is revealed.</p>

<p>Another important aspect is the option to join forces with other Kagglers and compete as a team. While it is possible to form a team with the intent to just average individual solutions to increase the chance of a competition result, the more interesting and long term beneficial approach is to choose team members you can learn from and discuss with. Not only helps teaming to connect with other data scientists across the globe but also enables you to learn how other people think and their diverse approaches help to look beyond your own nose.</p>

<p>I also want to discuss how kaggling improves your coding skills. When I started in 2017 it was common to submit to a competition by inferring a given test set with a model you trained locally and uploading your resulting predictions via a submission.csv file to Kaggle.</p>

<p>Nowadays, you have to create code in the form of a jupyter notebook or script within Kaggles infrastructure, which is then used to predict a completely hidden test set. This environment is not only ressource- but also runtime-restricted, which forces an efficient inference pipeline.</p>

<p>Moreover, having to share the same inference environment within a team leads to developing important software developer skills such as readable clean code which is easy to understand and editable/ extendable by your team members. Both, efficient coding, as well as focus on enabling easy collaboration, are crucial skills for “real life” machine learning projects.</p>

<p>In summary, I think intensely motivated confrontation with machine learning problems in a competitive environment together with the availability of knowledge, teaming experience and need for efficient coding skills offered by doing Kaggle competition(s) is magnitudes better than any regular study of machine learning in terms of quality and quantity.</p>

<p>…and by the way, it’s FREE.</p>

<h2 id="how-it-started">
<a class="anchor" href="#how-it-started" aria-hidden="true"><span class="octicon octicon-link"></span></a>How it started</h2>

<p>So why did I register on Kaggle?</p>

<p>After I studied business mathematics at the LMU in Munich, I was doing a PhD in mathematics with focus on modeling financial markets in cooperation with a large insurance company. 
Practically, I worked three days a week in the company and researched for my PhD in the remaining four. In the very last phase, after I submitted my thesis, I was waiting for all kinds of bureaucratic stuff to finally receive the PhD grade. So, suddenly I was facing a lot of free time. 
Since I had always been fascinated yet clueless with respect to artificial intelligence, I started to watch very basic YouTube videos about neural networks. I immediately was fascinated by the topic and followed up with a free coursera course where I not only learned a few basics but also did my first baby steps in coding with python. After that, I was looking for a dataset/ problem to further practice. That’s when I found Kaggle, I registered and with nothing to lose I joined my first competition: the TensorFlow Speech Recognition Challenge</p>

<h2 id="the-first-competition">
<a class="anchor" href="#the-first-competition" aria-hidden="true"><span class="octicon octicon-link"></span></a>The first competition</h2>

<p>In the TensorFlow Speech Recognition Challenge competitors were asked to classify speech commands (e.g. start, stop, yes, no, etc) contained in 1 sec long audio clips.</p>

<p>It certainly was a tough competition to begin my journey, but the small dataset made it accessible to beginners, enabling me to work on this competition with only a macbook and GCP credits awarded to newly registered students.</p>

<p>At that point I was not only unfamiliar with audio processing and how to model it using machine learning, but also a beginner when it comes to python and even more clueless with respect to tensorflow 0.x (pytorch and keras practically did not exist back then). So, I spent a huge portion on setting up a baseline and learning tensorflow which was way more granular in the pre-keras aera compared to today. I was struggling with a lot of simple obstacles like reading audio data, understanding preprocessing or mixing in background noise as augmentation. Once I finally had a working code, I just tried random model architectures without any plan - didn’t read much in the forum, didn’t read kernels.</p>

<p>Because I knew so little, I learned so much. It was mind blowing and so much fun, resulting in being one of the most pleasant competitions until now. I worked most of my free time on this competition and finished 218 out of 1313 teams, just missing any medal, but still not too bad for a total noob.
Reading the top solution summaries showed several mistakes I made, the most important being not to research established model building blocks like VGG or ResNet, but building something completely random by myself. Also my code was not suited for quick experimentations or reproducibility. Nevertheless, the game was on. I was determined to learn from my mistakes and do better in the next competition.</p>

<p>Realizing the fun I had with machine learning, I pursued a transition in my job by moving from risk management to a team which provided data science consulting.</p>

  </div><a class="u-url" href="/dieters-blog/kaggle/2022/06/23/chapter-1.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/dieters-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/dieters-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/dieters-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/dieters-blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/dieters-blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
